{"ast":null,"code":"import _defineProperty from \"@babel/runtime/helpers/defineProperty\";\nimport _slicedToArray from \"@babel/runtime/helpers/slicedToArray\";\n\nfunction _createForOfIteratorHelperLoose(o, allowArrayLike) { var it = typeof Symbol !== \"undefined\" && o[Symbol.iterator] || o[\"@@iterator\"]; if (it) return (it = it.call(o)).next.bind(it); if (Array.isArray(o) || (it = _unsupportedIterableToArray(o)) || allowArrayLike && o && typeof o.length === \"number\") { if (it) o = it; var i = 0; return function () { if (i >= o.length) return { done: true }; return { done: false, value: o[i++] }; }; } throw new TypeError(\"Invalid attempt to iterate non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); }\n\nfunction _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === \"string\") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === \"Object\" && o.constructor) n = o.constructor.name; if (n === \"Map\" || n === \"Set\") return Array.from(o); if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }\n\nfunction _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) { arr2[i] = arr[i]; } return arr2; }\n\nfunction ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); enumerableOnly && (symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; })), keys.push.apply(keys, symbols); } return keys; }\n\nfunction _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = null != arguments[i] ? arguments[i] : {}; i % 2 ? ownKeys(Object(source), !0).forEach(function (key) { _defineProperty(target, key, source[key]); }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)) : ownKeys(Object(source)).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } return target; }\n\nimport _regeneratorRuntime from \"@babel/runtime/regenerator\";\nimport * as React from 'react';\nimport * as Utils from \"./WebCameraUtils\";\nimport { FacingModeToCameraType } from \"./WebConstants\";\nvar VALID_SETTINGS_KEYS = ['autoFocus', 'flashMode', 'exposureCompensation', 'colorTemperature', 'iso', 'brightness', 'contrast', 'saturation', 'sharpness', 'focusDistance', 'whiteBalance', 'zoom'];\n\nfunction useLoadedVideo(video, onLoaded) {\n  React.useEffect(function () {\n    if (video) {\n      video.addEventListener('loadedmetadata', function () {\n        requestAnimationFrame(function () {\n          onLoaded();\n        });\n      });\n    }\n  }, [video]);\n}\n\nexport function useWebCameraStream(video, preferredType, settings, _ref) {\n  var onCameraReady = _ref.onCameraReady,\n      onMountError = _ref.onMountError;\n  var isStartingCamera = React.useRef(false);\n  var activeStreams = React.useRef([]);\n  var capabilities = React.useRef({\n    autoFocus: 'continuous',\n    flashMode: 'off',\n    whiteBalance: 'continuous',\n    zoom: 1\n  });\n\n  var _React$useState = React.useState(null),\n      _React$useState2 = _slicedToArray(_React$useState, 2),\n      stream = _React$useState2[0],\n      setStream = _React$useState2[1];\n\n  var mediaTrackSettings = React.useMemo(function () {\n    return stream ? stream.getTracks()[0].getSettings() : null;\n  }, [stream]);\n  var type = React.useMemo(function () {\n    if (!mediaTrackSettings) {\n      return null;\n    }\n\n    var _mediaTrackSettings$f = mediaTrackSettings.facingMode,\n        facingMode = _mediaTrackSettings$f === void 0 ? 'user' : _mediaTrackSettings$f;\n    return FacingModeToCameraType[facingMode];\n  }, [mediaTrackSettings]);\n  var getStreamDeviceAsync = React.useCallback(function _callee() {\n    return _regeneratorRuntime.async(function _callee$(_context) {\n      while (1) {\n        switch (_context.prev = _context.next) {\n          case 0:\n            _context.prev = 0;\n            _context.next = 3;\n            return _regeneratorRuntime.awrap(Utils.getPreferredStreamDevice(preferredType));\n\n          case 3:\n            return _context.abrupt(\"return\", _context.sent);\n\n          case 6:\n            _context.prev = 6;\n            _context.t0 = _context[\"catch\"](0);\n\n            if (__DEV__) {\n              console.warn(\"Error requesting UserMedia for type \\\"\" + preferredType + \"\\\":\", _context.t0);\n            }\n\n            if (onMountError) {\n              onMountError({\n                nativeEvent: _context.t0\n              });\n            }\n\n            return _context.abrupt(\"return\", null);\n\n          case 11:\n          case \"end\":\n            return _context.stop();\n        }\n      }\n    }, null, null, [[0, 6]], Promise);\n  }, [preferredType, onMountError]);\n  var resumeAsync = React.useCallback(function _callee2() {\n    var nextStream;\n    return _regeneratorRuntime.async(function _callee2$(_context2) {\n      while (1) {\n        switch (_context2.prev = _context2.next) {\n          case 0:\n            _context2.next = 2;\n            return _regeneratorRuntime.awrap(getStreamDeviceAsync());\n\n          case 2:\n            nextStream = _context2.sent;\n\n            if (!Utils.compareStreams(nextStream, stream)) {\n              _context2.next = 5;\n              break;\n            }\n\n            return _context2.abrupt(\"return\", false);\n\n          case 5:\n            if (!activeStreams.current.some(function (value) {\n              return value.id === (nextStream == null ? void 0 : nextStream.id);\n            })) {\n              activeStreams.current.push(nextStream);\n            }\n\n            setStream(nextStream);\n\n            if (onCameraReady) {\n              onCameraReady();\n            }\n\n            return _context2.abrupt(\"return\", false);\n\n          case 9:\n          case \"end\":\n            return _context2.stop();\n        }\n      }\n    }, null, null, null, Promise);\n  }, [getStreamDeviceAsync, setStream, onCameraReady, stream, activeStreams.current]);\n  React.useEffect(function () {\n    if (isStartingCamera.current) {\n      return;\n    }\n\n    isStartingCamera.current = true;\n    resumeAsync().then(function (isStarting) {\n      isStartingCamera.current = isStarting;\n    }).catch(function () {\n      isStartingCamera.current = false;\n    });\n  }, [preferredType]);\n  React.useEffect(function () {\n    var changes = {};\n\n    for (var _i = 0, _Object$keys = Object.keys(settings); _i < _Object$keys.length; _i++) {\n      var key = _Object$keys[_i];\n\n      if (!VALID_SETTINGS_KEYS.includes(key)) {\n        continue;\n      }\n\n      var nextValue = settings[key];\n\n      if (nextValue !== capabilities.current[key]) {\n        changes[key] = nextValue;\n      }\n    }\n\n    var hasChanges = !!Object.keys(changes).length;\n\n    var nextWebCameraSettings = _objectSpread(_objectSpread({}, capabilities.current), changes);\n\n    if (hasChanges) {\n      Utils.syncTrackCapabilities(preferredType, stream, changes);\n    }\n\n    capabilities.current = nextWebCameraSettings;\n  }, [settings.autoFocus, settings.flashMode, settings.exposureCompensation, settings.colorTemperature, settings.iso, settings.brightness, settings.contrast, settings.saturation, settings.sharpness, settings.focusDistance, settings.whiteBalance, settings.zoom]);\n  React.useEffect(function () {\n    if (!video.current) {\n      return;\n    }\n\n    Utils.setVideoSource(video.current, stream);\n  }, [video.current, stream]);\n  React.useEffect(function () {\n    return function () {\n      for (var _iterator = _createForOfIteratorHelperLoose(activeStreams.current), _step; !(_step = _iterator()).done;) {\n        var _stream = _step.value;\n        Utils.stopMediaStream(_stream);\n      }\n\n      if (video.current) {\n        Utils.setVideoSource(video.current, stream);\n      }\n    };\n  }, []);\n  useLoadedVideo(video.current, function () {\n    Utils.syncTrackCapabilities(preferredType, stream, capabilities.current);\n  });\n  return {\n    type: type,\n    mediaTrackSettings: mediaTrackSettings\n  };\n}","map":{"version":3,"mappings":";;;;;;;;;;;;;;AACA,OAAO,KAAKA,KAAZ,MAAuB,OAAvB;AACA,OAAO,KAAKC,KAAZ;AACA,SAASC,sBAAT;AACA,IAAMC,mBAAmB,GAAG,CACxB,WADwB,EAExB,WAFwB,EAGxB,sBAHwB,EAIxB,kBAJwB,EAKxB,KALwB,EAMxB,YANwB,EAOxB,UAPwB,EAQxB,YARwB,EASxB,WATwB,EAUxB,eAVwB,EAWxB,cAXwB,EAYxB,MAZwB,CAA5B;;AAcA,SAASC,cAAT,CAAwBC,KAAxB,EAA+BC,QAA/B,EAAyC;AACrCN,OAAK,CAACO,SAAN,CAAgB,YAAM;AAClB,QAAIF,KAAJ,EAAW;AACPA,WAAK,CAACG,gBAAN,CAAuB,gBAAvB,EAAyC,YAAM;AAI3CC,6BAAqB,CAAC,YAAM;AACxBH,kBAAQ;AACX,SAFoB,CAArB;AAGH,OAPD;AAQH;AACJ,GAXD,EAWG,CAACD,KAAD,CAXH;AAYH;;AACD,OAAO,SAASK,kBAAT,CAA4BL,KAA5B,EAAmCM,aAAnC,EAAkDC,QAAlD,QAA8F;AAAA,MAAhCC,aAAgC,QAAhCA,aAAgC;AAAA,MAAjBC,YAAiB,QAAjBA,YAAiB;AACjG,MAAMC,gBAAgB,GAAGf,KAAK,CAACgB,MAAN,CAAa,KAAb,CAAzB;AACA,MAAMC,aAAa,GAAGjB,KAAK,CAACgB,MAAN,CAAa,EAAb,CAAtB;AACA,MAAME,YAAY,GAAGlB,KAAK,CAACgB,MAAN,CAAa;AAC9BG,aAAS,EAAE,YADmB;AAE9BC,aAAS,EAAE,KAFmB;AAG9BC,gBAAY,EAAE,YAHgB;AAI9BC,QAAI,EAAE;AAJwB,GAAb,CAArB;;AAMA,wBAA4BtB,KAAK,CAACuB,QAAN,CAAe,IAAf,CAA5B;AAAA;AAAA,MAAOC,MAAP;AAAA,MAAeC,SAAf;;AACA,MAAMC,kBAAkB,GAAG1B,KAAK,CAAC2B,OAAN,CAAc,YAAM;AAC3C,WAAOH,MAAM,GAAGA,MAAM,CAACI,SAAP,GAAmB,CAAnB,EAAsBC,WAAtB,EAAH,GAAyC,IAAtD;AACH,GAF0B,EAExB,CAACL,MAAD,CAFwB,CAA3B;AAIA,MAAMM,IAAI,GAAG9B,KAAK,CAAC2B,OAAN,CAAc,YAAM;AAC7B,QAAI,CAACD,kBAAL,EAAyB;AACrB,aAAO,IAAP;AACH;;AAED,gCAAgCA,kBAAhC,CAAQK,UAAR;AAAA,QAAQA,UAAR,sCAAqB,MAArB;AACA,WAAO7B,sBAAsB,CAAC6B,UAAD,CAA7B;AACH,GAPY,EAOV,CAACL,kBAAD,CAPU,CAAb;AAQA,MAAMM,oBAAoB,GAAGhC,KAAK,CAACiC,WAAN,CAAkB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,6CAE1BhC,KAAK,CAACiC,wBAAN,CAA+BvB,aAA/B,CAF0B;;AAAA;AAAA;;AAAA;AAAA;AAAA;;AAKvC,gBAAIwB,OAAJ,EAAa;AACTC,qBAAO,CAACC,IAAR,4CAAqD1B,aAArD;AACH;;AACD,gBAAIG,YAAJ,EAAkB;AACdA,0BAAY,CAAC;AAAEwB,2BAAW;AAAb,eAAD,CAAZ;AACH;;AAVsC,6CAWhC,IAXgC;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAAlB,EAa1B,CAAC3B,aAAD,EAAgBG,YAAhB,CAb0B,CAA7B;AAcA,MAAMyB,WAAW,GAAGvC,KAAK,CAACiC,WAAN,CAAkB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,6CACTD,oBAAoB,EADX;;AAAA;AAC5BQ,sBAD4B;;AAAA,iBAE9BvC,KAAK,CAACwC,cAAN,CAAqBD,UAArB,EAAiChB,MAAjC,CAF8B;AAAA;AAAA;AAAA;;AAAA,8CAMvB,KANuB;;AAAA;AAUlC,gBAAI,CAACP,aAAa,CAACyB,OAAd,CAAsBC,IAAtB,CAA2B,UAACC,KAAD;AAAA,qBAAWA,KAAK,CAACC,EAAN,MAAaL,UAAb,oBAAaA,UAAU,CAAEK,EAAzB,CAAX;AAAA,aAA3B,CAAL,EAAyE;AACrE5B,2BAAa,CAACyB,OAAd,CAAsBI,IAAtB,CAA2BN,UAA3B;AACH;;AAEDf,qBAAS,CAACe,UAAD,CAAT;;AACA,gBAAI3B,aAAJ,EAAmB;AACfA,2BAAa;AAChB;;AAjBiC,8CAkB3B,KAlB2B;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAAlB,EAmBjB,CAACmB,oBAAD,EAAuBP,SAAvB,EAAkCZ,aAAlC,EAAiDW,MAAjD,EAAyDP,aAAa,CAACyB,OAAvE,CAnBiB,CAApB;AAoBA1C,OAAK,CAACO,SAAN,CAAgB,YAAM;AAElB,QAAIQ,gBAAgB,CAAC2B,OAArB,EAA8B;AAC1B;AACH;;AACD3B,oBAAgB,CAAC2B,OAAjB,GAA2B,IAA3B;AACAH,eAAW,GACNQ,IADL,CACU,UAACC,UAAD,EAAgB;AACtBjC,sBAAgB,CAAC2B,OAAjB,GAA2BM,UAA3B;AACH,KAHD,EAIKC,KAJL,CAIW,YAAM;AAEblC,sBAAgB,CAAC2B,OAAjB,GAA2B,KAA3B;AACH,KAPD;AAQH,GAdD,EAcG,CAAC/B,aAAD,CAdH;AAgBAX,OAAK,CAACO,SAAN,CAAgB,YAAM;AAClB,QAAM2C,OAAO,GAAG,EAAhB;;AACA,oCAAkBC,MAAM,CAACC,IAAP,CAAYxC,QAAZ,CAAlB,kCAAyC;AAApC,UAAMyC,GAAG,mBAAT;;AACD,UAAI,CAAClD,mBAAmB,CAACmD,QAApB,CAA6BD,GAA7B,CAAL,EAAwC;AACpC;AACH;;AACD,UAAME,SAAS,GAAG3C,QAAQ,CAACyC,GAAD,CAA1B;;AACA,UAAIE,SAAS,KAAKrC,YAAY,CAACwB,OAAb,CAAqBW,GAArB,CAAlB,EAA6C;AACzCH,eAAO,CAACG,GAAD,CAAP,GAAeE,SAAf;AACH;AACJ;;AAED,QAAMC,UAAU,GAAG,CAAC,CAACL,MAAM,CAACC,IAAP,CAAYF,OAAZ,EAAqBO,MAA1C;;AACA,QAAMC,qBAAqB,mCAAQxC,YAAY,CAACwB,OAArB,GAAiCQ,OAAjC,CAA3B;;AACA,QAAIM,UAAJ,EAAgB;AACZvD,WAAK,CAAC0D,qBAAN,CAA4BhD,aAA5B,EAA2Ca,MAA3C,EAAmD0B,OAAnD;AACH;;AACDhC,gBAAY,CAACwB,OAAb,GAAuBgB,qBAAvB;AACH,GAlBD,EAkBG,CACC9C,QAAQ,CAACO,SADV,EAECP,QAAQ,CAACQ,SAFV,EAGCR,QAAQ,CAACgD,oBAHV,EAIChD,QAAQ,CAACiD,gBAJV,EAKCjD,QAAQ,CAACkD,GALV,EAMClD,QAAQ,CAACmD,UANV,EAOCnD,QAAQ,CAACoD,QAPV,EAQCpD,QAAQ,CAACqD,UARV,EASCrD,QAAQ,CAACsD,SATV,EAUCtD,QAAQ,CAACuD,aAVV,EAWCvD,QAAQ,CAACS,YAXV,EAYCT,QAAQ,CAACU,IAZV,CAlBH;AAgCAtB,OAAK,CAACO,SAAN,CAAgB,YAAM;AAElB,QAAI,CAACF,KAAK,CAACqC,OAAX,EAAoB;AAChB;AACH;;AACDzC,SAAK,CAACmE,cAAN,CAAqB/D,KAAK,CAACqC,OAA3B,EAAoClB,MAApC;AACH,GAND,EAMG,CAACnB,KAAK,CAACqC,OAAP,EAAgBlB,MAAhB,CANH;AAOAxB,OAAK,CAACO,SAAN,CAAgB,YAAM;AAClB,WAAO,YAAM;AAET,2DAAqBU,aAAa,CAACyB,OAAnC,wCAA4C;AAAA,YAAjClB,OAAiC;AAExCvB,aAAK,CAACoE,eAAN,CAAsB7C,OAAtB;AACH;;AACD,UAAInB,KAAK,CAACqC,OAAV,EAAmB;AAEfzC,aAAK,CAACmE,cAAN,CAAqB/D,KAAK,CAACqC,OAA3B,EAAoClB,MAApC;AACH;AACJ,KAVD;AAWH,GAZD,EAYG,EAZH;AAcApB,gBAAc,CAACC,KAAK,CAACqC,OAAP,EAAgB,YAAM;AAChCzC,SAAK,CAAC0D,qBAAN,CAA4BhD,aAA5B,EAA2Ca,MAA3C,EAAmDN,YAAY,CAACwB,OAAhE;AACH,GAFa,CAAd;AAGA,SAAO;AACHZ,QAAI,EAAJA,IADG;AAEHJ,sBAAkB,EAAlBA;AAFG,GAAP;AAIH","names":["React","Utils","FacingModeToCameraType","VALID_SETTINGS_KEYS","useLoadedVideo","video","onLoaded","useEffect","addEventListener","requestAnimationFrame","useWebCameraStream","preferredType","settings","onCameraReady","onMountError","isStartingCamera","useRef","activeStreams","capabilities","autoFocus","flashMode","whiteBalance","zoom","useState","stream","setStream","mediaTrackSettings","useMemo","getTracks","getSettings","type","facingMode","getStreamDeviceAsync","useCallback","getPreferredStreamDevice","__DEV__","console","warn","nativeEvent","resumeAsync","nextStream","compareStreams","current","some","value","id","push","then","isStarting","catch","changes","Object","keys","key","includes","nextValue","hasChanges","length","nextWebCameraSettings","syncTrackCapabilities","exposureCompensation","colorTemperature","iso","brightness","contrast","saturation","sharpness","focusDistance","setVideoSource","stopMediaStream"],"sourceRoot":"","sources":["D:/Users/georg/Desktop/MAD/SpaceBook/node_modules/expo-camera/build/useWebCameraStream.js"],"sourcesContent":["/* eslint-env browser */\nimport * as React from 'react';\nimport * as Utils from './WebCameraUtils';\nimport { FacingModeToCameraType } from './WebConstants';\nconst VALID_SETTINGS_KEYS = [\n    'autoFocus',\n    'flashMode',\n    'exposureCompensation',\n    'colorTemperature',\n    'iso',\n    'brightness',\n    'contrast',\n    'saturation',\n    'sharpness',\n    'focusDistance',\n    'whiteBalance',\n    'zoom',\n];\nfunction useLoadedVideo(video, onLoaded) {\n    React.useEffect(() => {\n        if (video) {\n            video.addEventListener('loadedmetadata', () => {\n                // without this async block the constraints aren't properly applied to the camera,\n                // this means that if you were to turn on the torch and swap to the front camera,\n                // then swap back to the rear camera the torch setting wouldn't be applied.\n                requestAnimationFrame(() => {\n                    onLoaded();\n                });\n            });\n        }\n    }, [video]);\n}\nexport function useWebCameraStream(video, preferredType, settings, { onCameraReady, onMountError, }) {\n    const isStartingCamera = React.useRef(false);\n    const activeStreams = React.useRef([]);\n    const capabilities = React.useRef({\n        autoFocus: 'continuous',\n        flashMode: 'off',\n        whiteBalance: 'continuous',\n        zoom: 1,\n    });\n    const [stream, setStream] = React.useState(null);\n    const mediaTrackSettings = React.useMemo(() => {\n        return stream ? stream.getTracks()[0].getSettings() : null;\n    }, [stream]);\n    // The actual camera type - this can be different from the incoming camera type.\n    const type = React.useMemo(() => {\n        if (!mediaTrackSettings) {\n            return null;\n        }\n        // On desktop no value will be returned, in this case we should assume the cameraType is 'front'\n        const { facingMode = 'user' } = mediaTrackSettings;\n        return FacingModeToCameraType[facingMode];\n    }, [mediaTrackSettings]);\n    const getStreamDeviceAsync = React.useCallback(async () => {\n        try {\n            return await Utils.getPreferredStreamDevice(preferredType);\n        }\n        catch (nativeEvent) {\n            if (__DEV__) {\n                console.warn(`Error requesting UserMedia for type \"${preferredType}\":`, nativeEvent);\n            }\n            if (onMountError) {\n                onMountError({ nativeEvent });\n            }\n            return null;\n        }\n    }, [preferredType, onMountError]);\n    const resumeAsync = React.useCallback(async () => {\n        const nextStream = await getStreamDeviceAsync();\n        if (Utils.compareStreams(nextStream, stream)) {\n            // Do nothing if the streams are the same.\n            // This happens when the device only supports one camera (i.e. desktop) and the mode was toggled between front/back while already active.\n            // Without this check there is a screen flash while the video switches.\n            return false;\n        }\n        // Save a history of all active streams (usually 2+) so we can close them later.\n        // Keeping them open makes swapping camera types much faster.\n        if (!activeStreams.current.some((value) => value.id === nextStream?.id)) {\n            activeStreams.current.push(nextStream);\n        }\n        // Set the new stream -> update the video, settings, and actual camera type.\n        setStream(nextStream);\n        if (onCameraReady) {\n            onCameraReady();\n        }\n        return false;\n    }, [getStreamDeviceAsync, setStream, onCameraReady, stream, activeStreams.current]);\n    React.useEffect(() => {\n        // Restart the camera and guard concurrent actions.\n        if (isStartingCamera.current) {\n            return;\n        }\n        isStartingCamera.current = true;\n        resumeAsync()\n            .then((isStarting) => {\n            isStartingCamera.current = isStarting;\n        })\n            .catch(() => {\n            // ensure the camera can be started again.\n            isStartingCamera.current = false;\n        });\n    }, [preferredType]);\n    // Update the native camera with any custom capabilities.\n    React.useEffect(() => {\n        const changes = {};\n        for (const key of Object.keys(settings)) {\n            if (!VALID_SETTINGS_KEYS.includes(key)) {\n                continue;\n            }\n            const nextValue = settings[key];\n            if (nextValue !== capabilities.current[key]) {\n                changes[key] = nextValue;\n            }\n        }\n        // Only update the native camera if changes were found\n        const hasChanges = !!Object.keys(changes).length;\n        const nextWebCameraSettings = { ...capabilities.current, ...changes };\n        if (hasChanges) {\n            Utils.syncTrackCapabilities(preferredType, stream, changes);\n        }\n        capabilities.current = nextWebCameraSettings;\n    }, [\n        settings.autoFocus,\n        settings.flashMode,\n        settings.exposureCompensation,\n        settings.colorTemperature,\n        settings.iso,\n        settings.brightness,\n        settings.contrast,\n        settings.saturation,\n        settings.sharpness,\n        settings.focusDistance,\n        settings.whiteBalance,\n        settings.zoom,\n    ]);\n    React.useEffect(() => {\n        // set or unset the video source.\n        if (!video.current) {\n            return;\n        }\n        Utils.setVideoSource(video.current, stream);\n    }, [video.current, stream]);\n    React.useEffect(() => {\n        return () => {\n            // Clean up on dismount, this is important for making sure the camera light goes off when the component is removed.\n            for (const stream of activeStreams.current) {\n                // Close all open streams.\n                Utils.stopMediaStream(stream);\n            }\n            if (video.current) {\n                // Invalidate the video source.\n                Utils.setVideoSource(video.current, stream);\n            }\n        };\n    }, []);\n    // Update props when the video loads.\n    useLoadedVideo(video.current, () => {\n        Utils.syncTrackCapabilities(preferredType, stream, capabilities.current);\n    });\n    return {\n        type,\n        mediaTrackSettings,\n    };\n}\n//# sourceMappingURL=useWebCameraStream.js.map"]},"metadata":{},"sourceType":"module"}